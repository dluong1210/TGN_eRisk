{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8b7d372",
      "metadata": {},
      "outputs": [],
      "source": [
        "for file in all_file:\n",
        "    df = pd.read_parquet(file, columns=[\"userID\", \"parentID\", \"post_id\", \"embedding\"])\n",
        "    if df[\"embedding\"].isnull().any():\n",
        "        print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d851d412",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 1807 events to tgn_depression\\data\\sample_data\\metsadeer.csv\n",
            "Target subject: metsadeer\n",
            "Total synthetic deleted_* users: 188\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "subject_to_targetUser = {}\n",
        "\n",
        "\n",
        "def parse_datetime_to_timestamp(dt_str: str) -> float:\n",
        "\n",
        "    s = dt_str.replace(\" UTC\", \"\").strip()\n",
        "    return datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\").timestamp()\n",
        "\n",
        "\n",
        "def parse_subject_json_to_csv(\n",
        "    input_path: str,\n",
        "    output_dir: Optional[str] = None,\n",
        ") -> str:\n",
        "    input_path = Path(input_path)\n",
        "    \n",
        "    with input_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        threads = json.load(f)\n",
        "    \n",
        "    if len(threads) == 0:\n",
        "        raise ValueError(\"JSON file is empty\")\n",
        "    \n",
        "    # target_subject = threads[0].get(\"targetSubject\")\n",
        "    # if target_subject is None:\n",
        "    #     target_subject = input_path.stem\n",
        "    #     print(f\"Warning: No targetSubject found, using filename: {target_subject}\")\n",
        "    # else:\n",
        "    #     for thread in threads:\n",
        "    #         if thread.get(\"targetSubject\") != target_subject:\n",
        "    #             print(f\"Warning: Different targetSubject found: {thread.get('targetSubject')} vs {target_subject}\")\n",
        "    target_subject = input_path.stem\n",
        "    for thread in threads:\n",
        "        sub = thread.get(\"submission\") or {}\n",
        "        if sub.get(\"target\") is True:\n",
        "            target_subject = sub.get(\"user_id\") or target_subject\n",
        "            break\n",
        "    \n",
        "    if output_dir is None:\n",
        "        output_dir = input_path.parent\n",
        "    else:\n",
        "        output_dir = Path(output_dir)\n",
        "    \n",
        "    output_path = output_dir / f\"{target_subject}.csv\"\n",
        "    \n",
        "    events: List[Dict[str, Any]] = []\n",
        "    deleted_counter = 0\n",
        "\n",
        "    for thread in threads:\n",
        "        # submission_id = thread.get(\"submissionId\")\n",
        "        # submission_author = thread.get(\"author\")\n",
        "        # submission_date = thread.get(\"date\")\n",
        "        # submission_title = (thread.get(\"title\") or \"\").strip()\n",
        "        # submission_body = (thread.get(\"body\") or \"\").strip()\n",
        "        sub = thread.get(\"submission\") or {}\n",
        "        submission_id = sub.get(\"submission_id\")\n",
        "        submission_author = sub.get(\"user_id\")\n",
        "        submission_date = sub.get(\"created_utc\")\n",
        "        submission_title = (sub.get(\"title\") or \"\").strip()\n",
        "        submission_body = (sub.get(\"body\") or \"\").strip()\n",
        "\n",
        "        conversation_id = submission_id\n",
        "        id_to_author: Dict[str, str] = {}\n",
        "\n",
        "        if submission_id is None or submission_author is None or submission_date is None:\n",
        "            continue\n",
        "\n",
        "        if submission_author == \"AutoModerator\":\n",
        "            processed_submission_author: Optional[str] = None\n",
        "        else:\n",
        "            full_text = (submission_title + \"\\n\\n\" + submission_body).strip()\n",
        "            if full_text in (\"[deleted]\", \"[removed]\"):\n",
        "                processed_submission_author = None\n",
        "            else:\n",
        "                if submission_author == \"[deleted]\":\n",
        "                    processed_submission_author = f\"deleted_{deleted_counter}\"\n",
        "                    deleted_counter += 1\n",
        "                else:\n",
        "                    processed_submission_author = submission_author\n",
        "\n",
        "        if processed_submission_author is not None:\n",
        "            id_to_author[submission_id] = processed_submission_author\n",
        "            try:\n",
        "                ts = parse_datetime_to_timestamp(submission_date)\n",
        "            except Exception:\n",
        "                ts = None\n",
        "\n",
        "            events.append(\n",
        "                {\n",
        "                    \"userID\": processed_submission_author,\n",
        "                    \"parentID\": None,\n",
        "                    \"timestamp\": ts,\n",
        "                    \"post_id\": submission_id,\n",
        "                    \"conversation_id\": conversation_id,\n",
        "                    # \"body\": full_text,\n",
        "                }\n",
        "            )\n",
        "\n",
        "        comments = thread.get(\"comments\", []) or []\n",
        "\n",
        "        # Pass 1: build id_to_author cho comments\n",
        "        for c in comments:\n",
        "            # cid = c.get(\"commentId\")\n",
        "            # cauthor = c.get(\"author\")\n",
        "            cid = c.get(\"comment_id\")\n",
        "            cauthor = c.get(\"user_id\")\n",
        "            cbody = (c.get(\"body\") or \"\").strip()\n",
        "\n",
        "            if cid is None or cauthor is None:\n",
        "                continue\n",
        "\n",
        "            if cauthor == \"AutoModerator\":\n",
        "                continue\n",
        "\n",
        "            if cbody in (\"[deleted]\", \"[removed]\"):\n",
        "                continue\n",
        "\n",
        "            if cauthor == \"[deleted]\":\n",
        "                new_name = f\"deleted_{deleted_counter}\"\n",
        "                deleted_counter += 1\n",
        "                processed_author = new_name\n",
        "            else:\n",
        "                processed_author = cauthor\n",
        "\n",
        "            id_to_author[cid] = processed_author\n",
        "\n",
        "        # Pass 2: tạo events cho comments\n",
        "        for c in comments:\n",
        "            # comment_id = c.get(\"commentId\")\n",
        "            # author = c.get(\"author\")\n",
        "            # date_str = c.get(\"date\")\n",
        "            # parent_token = c.get(\"parent\")\n",
        "            comment_id = c.get(\"comment_id\")\n",
        "            author = c.get(\"user_id\")\n",
        "            date_str = c.get(\"created_utc\")\n",
        "            parent_token = c.get(\"parent_id\")\n",
        "            body = (c.get(\"body\") or \"\").strip()\n",
        "\n",
        "            if comment_id is None or author is None or date_str is None:\n",
        "                continue\n",
        "\n",
        "            if author == \"AutoModerator\":\n",
        "                continue\n",
        "\n",
        "            if body in (\"[deleted]\", \"[removed]\"):\n",
        "                continue\n",
        "\n",
        "            if comment_id not in id_to_author:\n",
        "                continue\n",
        "            processed_author = id_to_author[comment_id]\n",
        "\n",
        "            parent_author: Optional[str] = None\n",
        "            if parent_token and parent_token in id_to_author:\n",
        "                parent_author = id_to_author[parent_token]\n",
        "\n",
        "            try:\n",
        "                ts = parse_datetime_to_timestamp(date_str)\n",
        "            except Exception:\n",
        "                ts = None\n",
        "\n",
        "            events.append(\n",
        "                {\n",
        "                    \"userID\": processed_author,\n",
        "                    \"parentID\": parent_author,\n",
        "                    \"timestamp\": ts,\n",
        "                    \"post_id\": comment_id,\n",
        "                    \"conversation_id\": conversation_id,\n",
        "                    # \"body\": body,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    df = pd.DataFrame(events)\n",
        "    \n",
        "    expected_cols = [\"userID\", \"parentID\", \"timestamp\", \"post_id\", \"conversation_id\"]\n",
        "    for col in expected_cols:\n",
        "        if col not in df.columns:\n",
        "            df[col] = None\n",
        "    \n",
        "    df = df[expected_cols]\n",
        "    \n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    df.to_csv(output_path, index=False)\n",
        "    \n",
        "    print(f\"Saved {len(events)} events to {output_path}\")\n",
        "    print(f\"Target subject: {target_subject}\")\n",
        "    print(f\"Total synthetic deleted_* users: {deleted_counter}\")\n",
        "    \n",
        "    return str(output_path)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ví dụ sử dụng:\n",
        "    parse_subject_json_to_csv(\n",
        "        input_path=\"tgn_depression/data/sample_data/2022_subject1200.json\",\n",
        "    )\n",
        "    # Output: tgn_depression/data/sample_data/metsadeer.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d5748d",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data_embedding' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdata_embedding\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33m2022_subject1301\u001b[39m\u001b[33m\"\u001b[39m].keys().tolist()\n",
            "\u001b[31mNameError\u001b[39m: name 'data_embedding' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "post_ids_in_df = df[\"post_id\"].unique()\n",
        "\n",
        "if \"embedding\" not in df.columns:\n",
        "    df[\"embedding\"] = None\n",
        "\n",
        "for post_id, embedding in data_embedding[\"2022_subject1301\"].items():\n",
        "    if post_id in post_ids_in_df:\n",
        "        idx = df[\"post_id\"] == post_id\n",
        "        emb_np = np.array(embedding)\n",
        "        if emb_np.shape == (768,):\n",
        "            # Assign each row individually to avoid ValueError with ndarray/list assignment\n",
        "            for i in df.index[idx]:\n",
        "                df.at[i, \"embedding\"] = emb_np\n",
        "        else:\n",
        "            print(f\"Warning: Embedding for {post_id} does not have shape (768,): {emb_np.shape}\")\n",
        "    else:\n",
        "        print(f\"Warning: {post_id} not in df\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec916d51",
      "metadata": {},
      "outputs": [],
      "source": [
        "for subject in data_embedding.keys():\n",
        "    targetUser = subject_to_targetUser[subject]\n",
        "    if targetUser in neg_user:\n",
        "        df = pd.read_csv(f\"/kaggle/working/2022/neg/{targetUser}.csv\")\n",
        "        output_path = f\"/kaggle/working/2022/neg/{targetUser}.csv\"\n",
        "    elif targetUser in pos_user:\n",
        "        df = pd.read_csv(f\"/kaggle/working/2022/pos/{targetUser}.csv\")\n",
        "        output_path = f\"/kaggle/working/2022/pos/{targetUser}.csv\"\n",
        "    else:\n",
        "        print(f\"Cant find {targetUser}\")\n",
        "\n",
        "    if \"embedding\" not in df.columns:\n",
        "        df[\"embedding\"] = None\n",
        "        \n",
        "    post_ids_in_df = df[\"post_id\"].unique()\n",
        "    count_error_shape, count_error_post_id = 0, 0\n",
        "    for post_id, embedding in data_embedding[subject].items():\n",
        "        if post_id in post_ids_in_df:\n",
        "            idx = df[\"post_id\"] == post_id\n",
        "            emb_np = np.array(embedding)\n",
        "            if emb_np.shape == (1024,):\n",
        "                # Assign each row individually to avoid ValueError with ndarray/list assignment\n",
        "                for i in df.index[idx]:\n",
        "                    df.at[i, \"embedding\"] = emb_np\n",
        "            else:\n",
        "                count_error_shape += 1\n",
        "        else:\n",
        "            count_error_post_id += 1\n",
        "    print(f\"{targetUser}: Error shape: {count_error_shape}, Error post_id: {count_error_post_id}\")\n",
        "    df.to_csv(f\"/kaggle/working/2022/{subject}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94ea264a",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"/kaggle/input/erisk2025-t2-official/labels/2025.txt\", \"r\") as f:\n",
        "    for line in f:"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
